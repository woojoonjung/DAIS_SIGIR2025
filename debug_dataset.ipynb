{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from transformers import (\n",
    "    BertTokenizer\n",
    ")\n",
    "from dataset import (\n",
    "    fasttext_detect_language,\n",
    "    create_data,\n",
    "    JSONDataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.26.4'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import dataset\n",
    "\n",
    "# importlib.reload(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "dataset = JSONDataset(\n",
    "    path='./data/pretraining_data_movie.jsonl',\n",
    "    tokenizer=tokenizer,\n",
    "    max_length=512\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_id': 6609,\n",
       " 'name': 'Captain John Smith And Pocahontas',\n",
       " 'description': \"Captain John Smith And Pocahontas is a 1953 adventure film that tells the story of the early colonial period when the British began to explore America's east coast. The film follows the adventures of Captain John Smith, who is sent on a mission by England's King James to explore and establish a colony in the New World, which is now Virginia.The film begins with Captain John Smith, played by Anthony Dexter, setting sail from England to explore the New World. Upon landing, he immediately sets out to explore, and in doing so, he antagonizes a local tribe of Native Americans, led by Chief Powhatan, with whom he has many confrontations.During one of his outings, Smith meets Pocahontas, the daughter of Chief Powhatan. She is charmed by Smith, and the two begin to have a romantic relationship. However, their relationship is put to the test when the colonists come into conflict with the local tribes of Native Americans, who are not pleased with the colonists taking over their land.As tensions rise between the two groups, Pocahontas, played by Jody Lawrance, acts as the mediator between the two, trying to prevent a full-blown war from breaking out. Meanwhile, Smith falls out of\",\n",
       " 'director': {'name': 'Lew Landers'},\n",
       " 'datecreated': '1953',\n",
       " 'aggregaterating': {'ratingcount': '181',\n",
       "  'ratingvalue': '4.6',\n",
       "  'worstrating': '0',\n",
       "  'bestrating': '10'},\n",
       " 'duration': '1 hr 15 min',\n",
       " 'actor': [{'name': 'Anthony Dexter'},\n",
       "  {'name': 'Jody Lawrance'},\n",
       "  {'name': 'Alan Hale Jr.'}],\n",
       " 'contentrating': 'Approved',\n",
       " 'inlanguage': 'English',\n",
       " 'productioncompany': {'name': 'MGM'},\n",
       " 'producer': None,\n",
       " 'page_url': 'https://www.yidio.com/movie/captain-john-smith-and-pocahontas/29946'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'row_id': [2, 3, 4],\n",
       " 'name': [9],\n",
       " 'description': [20],\n",
       " 'director': [280],\n",
       " 'director.name': [283],\n",
       " 'datecreated': [291, 292, 293],\n",
       " 'aggregaterating': [297, 298],\n",
       " 'aggregaterating.ratingcount': [301, 302, 303],\n",
       " 'aggregaterating.ratingvalue': [307, 308, 309],\n",
       " 'aggregaterating.worstrating': [315, 316],\n",
       " 'aggregaterating.bestrating': [320, 321],\n",
       " 'duration': [327],\n",
       " 'actor': [334],\n",
       " 'actor[0].name': [338],\n",
       " 'actor[1].name': [346],\n",
       " 'actor[2].name': [355],\n",
       " 'contentrating': [365, 366],\n",
       " 'inlanguage': [370, 371, 372, 373],\n",
       " 'productioncompany': [377, 378, 379, 380],\n",
       " 'productioncompany.name': [383],\n",
       " 'producer': [389],\n",
       " 'page_url': [393, 394, 395, 396]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[200]['key_positions']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos: 0, token: [CLS]\n",
      "pos: 1, token: {\n",
      "pos: 2, token: row\n",
      "pos: 3, token: _\n",
      "pos: 4, token: id\n",
      "pos: 5, token: :\n",
      "pos: 6, token: 660\n",
      "pos: 7, token: ##9\n",
      "pos: 8, token: ,\n",
      "pos: 9, token: name\n",
      "pos: 10, token: :\n",
      "pos: 11, token: captain\n",
      "pos: 12, token: john\n",
      "pos: 13, token: smith\n",
      "pos: 14, token: and\n",
      "pos: 15, token: po\n",
      "pos: 16, token: ##ca\n",
      "pos: 17, token: ##hon\n",
      "pos: 18, token: ##tas\n",
      "pos: 19, token: ,\n",
      "pos: 20, token: description\n",
      "pos: 21, token: :\n",
      "pos: 22, token: captain\n",
      "pos: 23, token: john\n",
      "pos: 24, token: smith\n",
      "pos: 25, token: and\n",
      "pos: 26, token: po\n",
      "pos: 27, token: ##ca\n",
      "pos: 28, token: ##hon\n",
      "pos: 29, token: ##tas\n",
      "pos: 30, token: is\n",
      "pos: 31, token: a\n",
      "pos: 32, token: 1953\n",
      "pos: 33, token: adventure\n",
      "pos: 34, token: film\n",
      "pos: 35, token: that\n",
      "pos: 36, token: tells\n",
      "pos: 37, token: the\n",
      "pos: 38, token: story\n",
      "pos: 39, token: of\n",
      "pos: 40, token: the\n",
      "pos: 41, token: early\n",
      "pos: 42, token: colonial\n",
      "pos: 43, token: period\n",
      "pos: 44, token: when\n",
      "pos: 45, token: the\n",
      "pos: 46, token: british\n",
      "pos: 47, token: began\n",
      "pos: 48, token: to\n",
      "pos: 49, token: explore\n",
      "pos: 50, token: america\n",
      "pos: 51, token: '\n",
      "pos: 52, token: s\n",
      "pos: 53, token: east\n",
      "pos: 54, token: coast\n",
      "pos: 55, token: .\n",
      "pos: 56, token: the\n",
      "pos: 57, token: film\n",
      "pos: 58, token: follows\n",
      "pos: 59, token: the\n",
      "pos: 60, token: adventures\n",
      "pos: 61, token: of\n",
      "pos: 62, token: captain\n",
      "pos: 63, token: john\n",
      "pos: 64, token: smith\n",
      "pos: 65, token: ,\n",
      "pos: 66, token: who\n",
      "pos: 67, token: is\n",
      "pos: 68, token: sent\n",
      "pos: 69, token: on\n",
      "pos: 70, token: a\n",
      "pos: 71, token: mission\n",
      "pos: 72, token: by\n",
      "pos: 73, token: england\n",
      "pos: 74, token: '\n",
      "pos: 75, token: s\n",
      "pos: 76, token: king\n",
      "pos: 77, token: james\n",
      "pos: 78, token: to\n",
      "pos: 79, token: explore\n",
      "pos: 80, token: and\n",
      "pos: 81, token: establish\n",
      "pos: 82, token: a\n",
      "pos: 83, token: colony\n",
      "pos: 84, token: in\n",
      "pos: 85, token: the\n",
      "pos: 86, token: new\n",
      "pos: 87, token: world\n",
      "pos: 88, token: ,\n",
      "pos: 89, token: which\n",
      "pos: 90, token: is\n",
      "pos: 91, token: now\n",
      "pos: 92, token: virginia\n",
      "pos: 93, token: .\n",
      "pos: 94, token: the\n",
      "pos: 95, token: film\n",
      "pos: 96, token: begins\n",
      "pos: 97, token: with\n",
      "pos: 98, token: captain\n",
      "pos: 99, token: john\n",
      "pos: 100, token: smith\n",
      "pos: 101, token: ,\n",
      "pos: 102, token: played\n",
      "pos: 103, token: by\n",
      "pos: 104, token: anthony\n",
      "pos: 105, token: dexter\n",
      "pos: 106, token: ,\n",
      "pos: 107, token: setting\n",
      "pos: 108, token: sail\n",
      "pos: 109, token: from\n",
      "pos: 110, token: england\n",
      "pos: 111, token: to\n",
      "pos: 112, token: explore\n",
      "pos: 113, token: the\n",
      "pos: 114, token: new\n",
      "pos: 115, token: world\n",
      "pos: 116, token: .\n",
      "pos: 117, token: upon\n",
      "pos: 118, token: landing\n",
      "pos: 119, token: ,\n",
      "pos: 120, token: he\n",
      "pos: 121, token: immediately\n",
      "pos: 122, token: sets\n",
      "pos: 123, token: out\n",
      "pos: 124, token: to\n",
      "pos: 125, token: explore\n",
      "pos: 126, token: ,\n",
      "pos: 127, token: and\n",
      "pos: 128, token: in\n",
      "pos: 129, token: doing\n",
      "pos: 130, token: so\n",
      "pos: 131, token: ,\n",
      "pos: 132, token: he\n",
      "pos: 133, token: ant\n",
      "pos: 134, token: ##ago\n",
      "pos: 135, token: ##ni\n",
      "pos: 136, token: ##zes\n",
      "pos: 137, token: a\n",
      "pos: 138, token: local\n",
      "pos: 139, token: tribe\n",
      "pos: 140, token: of\n",
      "pos: 141, token: native\n",
      "pos: 142, token: americans\n",
      "pos: 143, token: ,\n",
      "pos: 144, token: led\n",
      "pos: 145, token: by\n",
      "pos: 146, token: chief\n",
      "pos: 147, token: pow\n",
      "pos: 148, token: ##hat\n",
      "pos: 149, token: ##an\n",
      "pos: 150, token: ,\n",
      "pos: 151, token: with\n",
      "pos: 152, token: whom\n",
      "pos: 153, token: he\n",
      "pos: 154, token: has\n",
      "pos: 155, token: many\n",
      "pos: 156, token: confrontation\n",
      "pos: 157, token: ##s\n",
      "pos: 158, token: .\n",
      "pos: 159, token: during\n",
      "pos: 160, token: one\n",
      "pos: 161, token: of\n",
      "pos: 162, token: his\n",
      "pos: 163, token: outing\n",
      "pos: 164, token: ##s\n",
      "pos: 165, token: ,\n",
      "pos: 166, token: smith\n",
      "pos: 167, token: meets\n",
      "pos: 168, token: po\n",
      "pos: 169, token: ##ca\n",
      "pos: 170, token: ##hon\n",
      "pos: 171, token: ##tas\n",
      "pos: 172, token: ,\n",
      "pos: 173, token: the\n",
      "pos: 174, token: daughter\n",
      "pos: 175, token: of\n",
      "pos: 176, token: chief\n",
      "pos: 177, token: pow\n",
      "pos: 178, token: ##hat\n",
      "pos: 179, token: ##an\n",
      "pos: 180, token: .\n",
      "pos: 181, token: she\n",
      "pos: 182, token: is\n",
      "pos: 183, token: charm\n",
      "pos: 184, token: ##ed\n",
      "pos: 185, token: by\n",
      "pos: 186, token: smith\n",
      "pos: 187, token: ,\n",
      "pos: 188, token: and\n",
      "pos: 189, token: the\n",
      "pos: 190, token: two\n",
      "pos: 191, token: begin\n",
      "pos: 192, token: to\n",
      "pos: 193, token: have\n",
      "pos: 194, token: a\n",
      "pos: 195, token: romantic\n",
      "pos: 196, token: relationship\n",
      "pos: 197, token: .\n",
      "pos: 198, token: however\n",
      "pos: 199, token: ,\n",
      "pos: 200, token: their\n",
      "pos: 201, token: relationship\n",
      "pos: 202, token: is\n",
      "pos: 203, token: put\n",
      "pos: 204, token: to\n",
      "pos: 205, token: the\n",
      "pos: 206, token: test\n",
      "pos: 207, token: when\n",
      "pos: 208, token: the\n",
      "pos: 209, token: colonists\n",
      "pos: 210, token: come\n",
      "pos: 211, token: into\n",
      "pos: 212, token: conflict\n",
      "pos: 213, token: with\n",
      "pos: 214, token: the\n",
      "pos: 215, token: local\n",
      "pos: 216, token: tribes\n",
      "pos: 217, token: of\n",
      "pos: 218, token: native\n",
      "pos: 219, token: americans\n",
      "pos: 220, token: ,\n",
      "pos: 221, token: who\n",
      "pos: 222, token: are\n",
      "pos: 223, token: not\n",
      "pos: 224, token: pleased\n",
      "pos: 225, token: with\n",
      "pos: 226, token: the\n",
      "pos: 227, token: colonists\n",
      "pos: 228, token: taking\n",
      "pos: 229, token: over\n",
      "pos: 230, token: their\n",
      "pos: 231, token: land\n",
      "pos: 232, token: .\n",
      "pos: 233, token: as\n",
      "pos: 234, token: tensions\n",
      "pos: 235, token: rise\n",
      "pos: 236, token: between\n",
      "pos: 237, token: the\n",
      "pos: 238, token: two\n",
      "pos: 239, token: groups\n",
      "pos: 240, token: ,\n",
      "pos: 241, token: po\n",
      "pos: 242, token: ##ca\n",
      "pos: 243, token: ##hon\n",
      "pos: 244, token: ##tas\n",
      "pos: 245, token: ,\n",
      "pos: 246, token: played\n",
      "pos: 247, token: by\n",
      "pos: 248, token: jody\n",
      "pos: 249, token: law\n",
      "pos: 250, token: ##rance\n",
      "pos: 251, token: ,\n",
      "pos: 252, token: acts\n",
      "pos: 253, token: as\n",
      "pos: 254, token: the\n",
      "pos: 255, token: media\n",
      "pos: 256, token: ##tor\n",
      "pos: 257, token: between\n",
      "pos: 258, token: the\n",
      "pos: 259, token: two\n",
      "pos: 260, token: ,\n",
      "pos: 261, token: trying\n",
      "pos: 262, token: to\n",
      "pos: 263, token: prevent\n",
      "pos: 264, token: a\n",
      "pos: 265, token: full\n",
      "pos: 266, token: -\n",
      "pos: 267, token: blown\n",
      "pos: 268, token: war\n",
      "pos: 269, token: from\n",
      "pos: 270, token: breaking\n",
      "pos: 271, token: out\n",
      "pos: 272, token: .\n",
      "pos: 273, token: meanwhile\n",
      "pos: 274, token: ,\n",
      "pos: 275, token: smith\n",
      "pos: 276, token: falls\n",
      "pos: 277, token: out\n",
      "pos: 278, token: of\n",
      "pos: 279, token: ,\n",
      "pos: 280, token: director\n",
      "pos: 281, token: :\n",
      "pos: 282, token: {\n",
      "pos: 283, token: name\n",
      "pos: 284, token: :\n",
      "pos: 285, token: lew\n",
      "pos: 286, token: land\n",
      "pos: 287, token: ##ers\n",
      "pos: 288, token: ,\n",
      "pos: 289, token: }\n",
      "pos: 290, token: ,\n",
      "pos: 291, token: date\n",
      "pos: 292, token: ##cre\n",
      "pos: 293, token: ##ated\n",
      "pos: 294, token: :\n",
      "pos: 295, token: 1953\n",
      "pos: 296, token: ,\n",
      "pos: 297, token: aggregate\n",
      "pos: 298, token: ##rating\n",
      "pos: 299, token: :\n",
      "pos: 300, token: {\n",
      "pos: 301, token: rating\n",
      "pos: 302, token: ##co\n",
      "pos: 303, token: ##unt\n",
      "pos: 304, token: :\n",
      "pos: 305, token: 181\n",
      "pos: 306, token: ,\n",
      "pos: 307, token: rating\n",
      "pos: 308, token: ##val\n",
      "pos: 309, token: ##ue\n",
      "pos: 310, token: :\n",
      "pos: 311, token: 4\n",
      "pos: 312, token: .\n",
      "pos: 313, token: 6\n",
      "pos: 314, token: ,\n",
      "pos: 315, token: worst\n",
      "pos: 316, token: ##rating\n",
      "pos: 317, token: :\n",
      "pos: 318, token: 0\n",
      "pos: 319, token: ,\n",
      "pos: 320, token: best\n",
      "pos: 321, token: ##rating\n",
      "pos: 322, token: :\n",
      "pos: 323, token: 10\n",
      "pos: 324, token: ,\n",
      "pos: 325, token: }\n",
      "pos: 326, token: ,\n",
      "pos: 327, token: duration\n",
      "pos: 328, token: :\n",
      "pos: 329, token: 1\n",
      "pos: 330, token: hr\n",
      "pos: 331, token: 15\n",
      "pos: 332, token: min\n",
      "pos: 333, token: ,\n",
      "pos: 334, token: actor\n",
      "pos: 335, token: :\n",
      "pos: 336, token: [\n",
      "pos: 337, token: {\n",
      "pos: 338, token: name\n",
      "pos: 339, token: :\n",
      "pos: 340, token: anthony\n",
      "pos: 341, token: dexter\n",
      "pos: 342, token: ,\n",
      "pos: 343, token: }\n",
      "pos: 344, token: ,\n",
      "pos: 345, token: {\n",
      "pos: 346, token: name\n",
      "pos: 347, token: :\n",
      "pos: 348, token: jody\n",
      "pos: 349, token: law\n",
      "pos: 350, token: ##rance\n",
      "pos: 351, token: ,\n",
      "pos: 352, token: }\n",
      "pos: 353, token: ,\n",
      "pos: 354, token: {\n",
      "pos: 355, token: name\n",
      "pos: 356, token: :\n",
      "pos: 357, token: alan\n",
      "pos: 358, token: hale\n",
      "pos: 359, token: jr\n",
      "pos: 360, token: .\n",
      "pos: 361, token: ,\n",
      "pos: 362, token: }\n",
      "pos: 363, token: ]\n",
      "pos: 364, token: ,\n",
      "pos: 365, token: content\n",
      "pos: 366, token: ##rating\n",
      "pos: 367, token: :\n",
      "pos: 368, token: approved\n",
      "pos: 369, token: ,\n",
      "pos: 370, token: in\n",
      "pos: 371, token: ##lang\n",
      "pos: 372, token: ##ua\n",
      "pos: 373, token: ##ge\n",
      "pos: 374, token: :\n",
      "pos: 375, token: english\n",
      "pos: 376, token: ,\n",
      "pos: 377, token: production\n",
      "pos: 378, token: ##com\n",
      "pos: 379, token: ##pan\n",
      "pos: 380, token: ##y\n",
      "pos: 381, token: :\n",
      "pos: 382, token: {\n",
      "pos: 383, token: name\n",
      "pos: 384, token: :\n",
      "pos: 385, token: mgm\n",
      "pos: 386, token: ,\n",
      "pos: 387, token: }\n",
      "pos: 388, token: ,\n",
      "pos: 389, token: producer\n",
      "pos: 390, token: :\n",
      "pos: 391, token: none\n",
      "pos: 392, token: ,\n",
      "pos: 393, token: page\n",
      "pos: 394, token: _\n",
      "pos: 395, token: ur\n",
      "pos: 396, token: ##l\n",
      "pos: 397, token: :\n",
      "pos: 398, token: https\n",
      "pos: 399, token: :\n",
      "pos: 400, token: /\n",
      "pos: 401, token: /\n",
      "pos: 402, token: www\n",
      "pos: 403, token: .\n",
      "pos: 404, token: yi\n",
      "pos: 405, token: ##dio\n",
      "pos: 406, token: .\n",
      "pos: 407, token: com\n",
      "pos: 408, token: /\n",
      "pos: 409, token: movie\n",
      "pos: 410, token: /\n",
      "pos: 411, token: captain\n",
      "pos: 412, token: -\n",
      "pos: 413, token: john\n",
      "pos: 414, token: -\n",
      "pos: 415, token: smith\n",
      "pos: 416, token: -\n",
      "pos: 417, token: and\n",
      "pos: 418, token: -\n",
      "pos: 419, token: po\n",
      "pos: 420, token: ##ca\n",
      "pos: 421, token: ##hon\n",
      "pos: 422, token: ##tas\n",
      "pos: 423, token: /\n",
      "pos: 424, token: 299\n",
      "pos: 425, token: ##46\n",
      "pos: 426, token: ,\n",
      "pos: 427, token: }\n",
      "pos: 428, token: [SEP]\n",
      "pos: 429, token: [PAD]\n",
      "pos: 430, token: [PAD]\n",
      "pos: 431, token: [PAD]\n",
      "pos: 432, token: [PAD]\n",
      "pos: 433, token: [PAD]\n",
      "pos: 434, token: [PAD]\n",
      "pos: 435, token: [PAD]\n",
      "pos: 436, token: [PAD]\n",
      "pos: 437, token: [PAD]\n",
      "pos: 438, token: [PAD]\n",
      "pos: 439, token: [PAD]\n",
      "pos: 440, token: [PAD]\n",
      "pos: 441, token: [PAD]\n",
      "pos: 442, token: [PAD]\n",
      "pos: 443, token: [PAD]\n",
      "pos: 444, token: [PAD]\n",
      "pos: 445, token: [PAD]\n",
      "pos: 446, token: [PAD]\n",
      "pos: 447, token: [PAD]\n",
      "pos: 448, token: [PAD]\n",
      "pos: 449, token: [PAD]\n",
      "pos: 450, token: [PAD]\n",
      "pos: 451, token: [PAD]\n",
      "pos: 452, token: [PAD]\n",
      "pos: 453, token: [PAD]\n",
      "pos: 454, token: [PAD]\n",
      "pos: 455, token: [PAD]\n",
      "pos: 456, token: [PAD]\n",
      "pos: 457, token: [PAD]\n",
      "pos: 458, token: [PAD]\n",
      "pos: 459, token: [PAD]\n",
      "pos: 460, token: [PAD]\n",
      "pos: 461, token: [PAD]\n",
      "pos: 462, token: [PAD]\n",
      "pos: 463, token: [PAD]\n",
      "pos: 464, token: [PAD]\n",
      "pos: 465, token: [PAD]\n",
      "pos: 466, token: [PAD]\n",
      "pos: 467, token: [PAD]\n",
      "pos: 468, token: [PAD]\n",
      "pos: 469, token: [PAD]\n",
      "pos: 470, token: [PAD]\n",
      "pos: 471, token: [PAD]\n",
      "pos: 472, token: [PAD]\n",
      "pos: 473, token: [PAD]\n",
      "pos: 474, token: [PAD]\n",
      "pos: 475, token: [PAD]\n",
      "pos: 476, token: [PAD]\n",
      "pos: 477, token: [PAD]\n",
      "pos: 478, token: [PAD]\n",
      "pos: 479, token: [PAD]\n",
      "pos: 480, token: [PAD]\n",
      "pos: 481, token: [PAD]\n",
      "pos: 482, token: [PAD]\n",
      "pos: 483, token: [PAD]\n",
      "pos: 484, token: [PAD]\n",
      "pos: 485, token: [PAD]\n",
      "pos: 486, token: [PAD]\n",
      "pos: 487, token: [PAD]\n",
      "pos: 488, token: [PAD]\n",
      "pos: 489, token: [PAD]\n",
      "pos: 490, token: [PAD]\n",
      "pos: 491, token: [PAD]\n",
      "pos: 492, token: [PAD]\n",
      "pos: 493, token: [PAD]\n",
      "pos: 494, token: [PAD]\n",
      "pos: 495, token: [PAD]\n",
      "pos: 496, token: [PAD]\n",
      "pos: 497, token: [PAD]\n",
      "pos: 498, token: [PAD]\n",
      "pos: 499, token: [PAD]\n",
      "pos: 500, token: [PAD]\n",
      "pos: 501, token: [PAD]\n",
      "pos: 502, token: [PAD]\n",
      "pos: 503, token: [PAD]\n",
      "pos: 504, token: [PAD]\n",
      "pos: 505, token: [PAD]\n",
      "pos: 506, token: [PAD]\n",
      "pos: 507, token: [PAD]\n",
      "pos: 508, token: [PAD]\n",
      "pos: 509, token: [PAD]\n",
      "pos: 510, token: [PAD]\n",
      "pos: 511, token: [PAD]\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer.convert_ids_to_tokens(dataset[200]['input_ids'])\n",
    "for i in range(len(tokens)):\n",
    "    print(f\"pos: {i}, token: {tokens[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Func test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _serialize(json_obj):\n",
    "    \"\"\"\n",
    "    Serialize the JSON object with clear hierarchical key representation.\n",
    "    \"\"\"\n",
    "    def serialize_recursive(obj, parent_key=\"\"):\n",
    "        parts = []\n",
    "        if isinstance(obj, dict):\n",
    "            parts.append(\"{\")\n",
    "            for k, v in obj.items():\n",
    "                full_key = f\"{parent_key}.{k}\" if parent_key else k\n",
    "                parts.append(f\"{k}: {serialize_recursive(v, full_key)}\")\n",
    "                parts.append(\",\")\n",
    "            parts.append(\"}\")\n",
    "        elif isinstance(obj, list):\n",
    "            parts.append(\"[\")\n",
    "            parts.append(\", \".join([serialize_recursive(item, parent_key) for item in obj]))\n",
    "            parts.append(\"]\")\n",
    "        else:\n",
    "            parts.append(str(obj))\n",
    "        return \" \".join(parts)\n",
    "\n",
    "    serialized = serialize_recursive(json_obj)\n",
    "    return serialized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = create_data('./data/pretraining_data_product.jsonl', 'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_serialize = _serialize(test_data[1])\n",
    "print(test_serialize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
