{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU is available and will be used.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Feb 17 03:49:14 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.127.05             Driver Version: 550.127.05     CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA RTX 6000 Ada Gene...    On  |   00000000:01:00.0 Off |                  Off |\n",
      "| 30%   45C    P2             88W /  300W |    2060MiB /  49140MiB |      9%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    BertTokenizer, BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling,\n",
    "    TapasTokenizer, TapasForMaskedLM,\n",
    "    AdamW, get_scheduler\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model_complete import JSONBERT_COMPLETE\n",
    "from no_cl import JSONBERT_INTERPOLATE\n",
    "from no_ip_alpha_0 import JSONBERT_NEWLOSS_0\n",
    "from no_ip_alpha_1 import JSONBERT_NEWLOSS_1\n",
    "from dataset import JSONDataset, JSONDataCollator, create_data\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/woojun/')\n",
    "\n",
    "from utils import (\n",
    "    _serialize_vanilla,\n",
    "    _serialize,\n",
    "    tokenize_table,\n",
    "    _find_positions,\n",
    "    mask_entry,\n",
    "    predict_masked_tokens,\n",
    "    evaluate_masked_prediction,\n",
    "    get_table_embedding,\n",
    "    prepare_Xy,\n",
    "    train_eval_rf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# import utils\n",
    "\n",
    "# importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer & config\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From pre-trained\n",
    "\n",
    "* BERT\n",
    "* TaPas\n",
    "* TaBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertForMaskedLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# BERT\n",
    "bert_base = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "bert_base = bert_base.to(device)\n",
    "\n",
    "\n",
    "# TaPas\n",
    "tapas_name = \"google/tapas-base-masklm\"\n",
    "tapas_tokenizer = TapasTokenizer.from_pretrained(tapas_name)\n",
    "tapas = TapasForMaskedLM.from_pretrained(tapas_name)\n",
    "tapas.to(device)\n",
    "\n",
    "\n",
    "# # TaBERT\n",
    "tabert = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "model_path = './TaBERT/tabert_base_k1'\n",
    "tabert_state_dict = torch.load(os.path.join(model_path, \"model.bin\"))\n",
    "\n",
    "state_dict = {}\n",
    "for key, value in state_dict.items():\n",
    "    new_key = key.replace(\"_bert_model.\", \"\")\n",
    "    state_dict[new_key] = value\n",
    "\n",
    "tabert.load_state_dict(state_dict, strict=False)\n",
    "tabert = tabert.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domain-specific pre-trained\n",
    "\n",
    "* Ours\n",
    "* -no CL (lambda = 0)\n",
    "* -no Interpolation (alpha = 0)\n",
    "* -no Interpolation (alpha = 1)\n",
    "* -no Header Embedding Layer (alpha = 1, lambda = 0)\n",
    "---\n",
    "* BERT trained with text serialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT loaded from ./models/product_complete/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_INTERPOLATE loaded from ./models/product_no_cl/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_NEWLOSS loaded from ./models/product_alpha_0/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_NEWLOSS loaded from ./models/product_alpha_1/epoch-9\n"
     ]
    }
   ],
   "source": [
    "# Product\n",
    "\n",
    "ours_path_product = './models/product_complete/epoch-9'\n",
    "no_cl_path_product = './models/product_no_cl/epoch-9'\n",
    "alpha_0_path_product = './models/product_alpha_0/epoch-9'\n",
    "alpha_1_path_product = './models/product_alpha_1/epoch-9'\n",
    "no_hel_path_product = './models/product_no_hel/epoch-9'\n",
    "bert_path_product = './models/product_bert/epoch-9'\n",
    "\n",
    "ours_product = JSONBERT_COMPLETE(config, tokenizer, ours_path_product)\n",
    "ours_product = ours_product.to(device)\n",
    "\n",
    "no_cl_product = JSONBERT_INTERPOLATE(config, tokenizer, no_cl_path_product)\n",
    "no_cl_product = no_cl_product.to(device)\n",
    "\n",
    "alpha_0_product = JSONBERT_NEWLOSS_0(config, tokenizer, alpha_0_path_product)\n",
    "alpha_0_product = alpha_0_product.to(device)\n",
    "\n",
    "alpha_1_product = JSONBERT_NEWLOSS_1(config, tokenizer, alpha_1_path_product)\n",
    "alpha_1_product = alpha_1_product.to(device)\n",
    "\n",
    "no_hel_product = BertForMaskedLM.from_pretrained(no_hel_path_product, local_files_only=True)\n",
    "no_hel_product = no_hel_product.to(device)\n",
    "\n",
    "bert_product = BertForMaskedLM.from_pretrained(bert_path_product, local_files_only=True)\n",
    "bert_product = bert_product.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT loaded from ./models/movie_complete/epoch-9\n"
     ]
    }
   ],
   "source": [
    "# Movie\n",
    "\n",
    "ours_path_movie = './models/movie_complete/epoch-9'\n",
    "no_cl_path_movie = './models/movie_no_cl/epoch-9'\n",
    "alpha_0_path_movie = './models/movie_alpha_0/epoch-9'\n",
    "alpha_1_path_movie = './models/movie_alpha_1/epoch-9'\n",
    "no_hel_path_movie = './models/movie_no_hel/epoch-9'\n",
    "bert_path_movie = './models/movie_bert/epoch-9'\n",
    "\n",
    "ours_movie = JSONBERT_COMPLETE(config, tokenizer, ours_path_movie)\n",
    "ours_movie = ours_movie.to(device)\n",
    "\n",
    "no_cl_movie = JSONBERT_INTERPOLATE(config, tokenizer, no_cl_path_movie)\n",
    "no_cl_movie = no_cl_movie.to(device)\n",
    "\n",
    "alpha_0_movie = JSONBERT_NEWLOSS_0(config, tokenizer, alpha_0_path_movie)\n",
    "alpha_0_movie = alpha_0_movie.to(device)\n",
    "\n",
    "alpha_1_movie = JSONBERT_NEWLOSS_1(config, tokenizer, alpha_1_path_movie)\n",
    "alpha_1_movie = alpha_1_movie.to(device)\n",
    "\n",
    "no_hel_movie = BertForMaskedLM.from_pretrained(no_hel_path_movie, local_files_only=True)\n",
    "no_hel_movie = no_hel_movie.to(device)\n",
    "\n",
    "bert_movie = BertForMaskedLM.from_pretrained(bert_path_movie, local_files_only=True)\n",
    "bert_movie = bert_movie.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "pretraining_movie_path = './data/pretraining_data_movie.jsonl'\n",
    "pretraining_product_path = './data/pretraining_data_product.jsonl'\n",
    "\n",
    "movie_path = './data/Movie_top100'\n",
    "product_path = './data/Product_top100'\n",
    "\n",
    "movie = create_data(movie_path, path_is=\"test\", sample_num=20, pretraining_path=pretraining_movie_path)\n",
    "product = create_data(product_path, path_is=\"test\", sample_num=20, pretraining_path=pretraining_product_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(movie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Masked Prediction\n",
    "\n",
    "**In-domain MP**\n",
    "* Unseen rows when pre-training\n",
    "* Additional 2 columns that are unseen during pre-training\n",
    "* Trained with ___ samples, tested with 1000 samples\n",
    "\n",
    "**Cross-domain MP**\n",
    "* Tested on unseen domains for BERT & Our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-domain: Movie\n",
    "\n",
    "# Pre-trained: BERT, TaPas, TaBERT\n",
    "evaluate_masked_prediction(movie, 'Key', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', tapas, tapas_tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', tabert, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(movie, 'Value', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', tapas, tapas_tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', tabert, tokenizer)\n",
    "\n",
    "\n",
    "# Domain-specific pre-trained: Ours, No CL, No IP_a0, No IP_a1, No HEL, trained BERT\n",
    "evaluate_masked_prediction(movie, 'Key', ours_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', no_cl_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', alpha_0_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', alpha_1_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', no_hel_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', bert_movie, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(movie, 'Value', ours_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', no_cl_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', alpha_0_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', alpha_1_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', no_hel_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', bert_movie, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In-domain: Product\n",
    "\n",
    "# Pre-trained: BERT, TaPas, TaBERT\n",
    "evaluate_masked_prediction(product, 'Key', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', tapas, tapas_tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', tabert, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(product, 'Value', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', tapas, tapas_tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', tabert, tokenizer)\n",
    "\n",
    "\n",
    "# Domain-specific pre-trained: Ours, No CL, No IP_a0, No IP_a1, No HEL, trained BERT\n",
    "evaluate_masked_prediction(product, 'Key', ours_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', no_cl_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', alpha_0_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', alpha_1_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', no_hel_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', bert_product, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(product, 'Value', ours_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', no_cl_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', alpha_0_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', alpha_1_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', no_hel_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', bert_product, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-domain\n",
    "\n",
    "# Trained on Product -> Tested on Movie\n",
    "evaluate_masked_prediction(movie, 'Key', ours_product, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', ours_product, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(movie, 'Key', bert_product, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', bert_product, tokenizer)\n",
    "\n",
    "\n",
    "# Trained on Movie -> Tested on Product\n",
    "evaluate_masked_prediction(product, 'Key', ours_movie, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', ours_movie, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(product, 'Key', bert_movie, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', bert_movie, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tuning Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load models\n",
    "\n",
    "# ours_movie_lambda_04 = JSONBERT_COMPLETE(config, tokenizer, \"models/lambda_04_movie/epoch-9\", lambda_align=0.4)\n",
    "# ours_movie_lambda_045 = JSONBERT_COMPLETE(config, tokenizer, \"models/lambda_045_movie/epoch-9\", lambda_align=0.45)\n",
    "\n",
    "# ours_movie_lambda_04 = ours_movie_lambda_04.to(device)\n",
    "# ours_movie_lambda_045 = ours_movie_lambda_045.to(device)\n",
    "\n",
    "# ours_product_lambda_04 = JSONBERT_COMPLETE(config, tokenizer, \"models/lambda_04_product/epoch-9\", lambda_align=0.4)\n",
    "# ours_product_lambda_045 = JSONBERT_COMPLETE(config, tokenizer, \"models/lambda_045_product/epoch-9\", lambda_align=0.45)\n",
    "\n",
    "# ours_product_lambda_04 = ours_product_lambda_04.to(device)\n",
    "# ours_product_lambda_045 = ours_product_lambda_045.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In-domain: Movie\n",
    "\n",
    "# evaluate_masked_prediction(movie, 'Key', ours_movie_lambda_04, tokenizer)\n",
    "# evaluate_masked_prediction(movie, 'Key', ours_movie_lambda_045, tokenizer)\n",
    "\n",
    "# evaluate_masked_prediction(movie, 'Value', ours_movie_lambda_04, tokenizer)\n",
    "# evaluate_masked_prediction(movie, 'Value', ours_movie_lambda_045, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # In-domain: Product\n",
    "\n",
    "# evaluate_masked_prediction(product, 'Key', ours_product_lambda_04, tokenizer)\n",
    "# evaluate_masked_prediction(product, 'Key', ours_product_lambda_045, tokenizer)\n",
    "\n",
    "# evaluate_masked_prediction(product, 'Value', ours_product_lambda_04, tokenizer)\n",
    "# evaluate_masked_prediction(product, 'Value', ours_product_lambda_045, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Cross-domain\n",
    "\n",
    "# # Trained on Product -> Tested on Movie\n",
    "# evaluate_masked_prediction(movie, 'Key', ours_product_lambda_03, tokenizer)\n",
    "# evaluate_masked_prediction(movie, 'Value', ours_product_lambda_03, tokenizer)\n",
    "\n",
    "# evaluate_masked_prediction(movie, 'Key', ours_product_lambda_05, tokenizer)\n",
    "# evaluate_masked_prediction(movie, 'Value', ours_product_lambda_05, tokenizer)\n",
    "\n",
    "\n",
    "# # Trained on Movie -> Tested on Product\n",
    "# evaluate_masked_prediction(product, 'Key', ours_movie_lambda_03, tokenizer)\n",
    "# evaluate_masked_prediction(product, 'Value', ours_movie_lambda_03, tokenizer)\n",
    "\n",
    "# evaluate_masked_prediction(product, 'Key', ours_movie_lambda_05, tokenizer)\n",
    "# evaluate_masked_prediction(product, 'Value', ours_movie_lambda_05, tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning tools #\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "### For Ours\n",
    "def fine_tune_model(model, dataloader, optimizer, scheduler, device, epochs=3):\n",
    "    model.to(device)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0\n",
    "        progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "\n",
    "        for batch in progress_bar:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if hasattr(model, \"key_embedding\"):\n",
    "                outputs = model(\n",
    "                    input_ids=input_ids, \n",
    "                    attention_mask=attention_mask, \n",
    "                    labels=labels, \n",
    "                    key_positions=batch[\"key_positions\"],\n",
    "                    compute_alignment_loss=True\n",
    "                )\n",
    "                loss = outputs[\"loss\"]\n",
    "            else:\n",
    "                outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "                loss = outputs.loss\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "            progress_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        print(f\"Epoch {epoch + 1} Loss: {epoch_loss / len(dataloader):.4f}\")\n",
    "\n",
    "def create_optimizer_and_scheduler(model, dataloader, learning_rate, epochs):\n",
    "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "    num_training_steps = len(dataloader) * epochs\n",
    "    scheduler = get_scheduler(\n",
    "        \"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
    "    )\n",
    "    return optimizer, scheduler\n",
    "\n",
    "### For TaPas\n",
    "def apply_masking(inputs, mask_prob=0.15):\n",
    "    \"\"\" Apply MLM-style random masking to TAPAS input_ids. \"\"\"\n",
    "    labels = inputs['input_ids'].clone()\n",
    "    mask = torch.full(labels.shape, mask_prob)\n",
    "    \n",
    "    # Apply special token mask (avoid masking special tokens)\n",
    "    special_tokens_mask = tapas_tokenizer.get_special_tokens_mask(labels.tolist(), already_has_special_tokens=True)\n",
    "    special_tokens_mask = torch.tensor(special_tokens_mask, dtype=torch.bool)\n",
    "\n",
    "    # Apply masking\n",
    "    mask.masked_fill_(special_tokens_mask, value=0.0)\n",
    "    masked_indices = torch.bernoulli(mask).bool()\n",
    "    labels[~masked_indices] = -100  # Ignore unmasked tokens in loss\n",
    "    inputs['input_ids'][masked_indices] = tapas_tokenizer.mask_token_id \n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "def prepare_tapas_traindata(entry):\n",
    "    \"\"\" Tokenize tabular data for TAPAS while handling batch structure. \"\"\"\n",
    "    str_entry = {k: str(v) for k, v in entry.items()}\n",
    "    table = pd.DataFrame([str_entry]) \n",
    "    inputs = tapas_tokenizer(table=table, queries=[\"What is the missing value?\"], padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(device)\n",
    "    inputs, labels = apply_masking(inputs)\n",
    "\n",
    "    return inputs, labels\n",
    "\n",
    "def fine_tune_tapas(tapas, path, epochs):\n",
    "    with open(path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "        lines = f.readlines()\n",
    "    df = pd.read_csv(StringIO(''.join(lines)))\n",
    "    data = df.to_dict(orient=\"records\")\n",
    "\n",
    "    train_data = [prepare_tapas_traindata(row) for row in data]\n",
    "\n",
    "    # Convert train_data to tensors\n",
    "    input_tensors = {k: torch.cat([entry[0][k] for entry in train_data]) for k in train_data[0][0].keys()}\n",
    "    label_tensors = torch.cat([entry[1] for entry in train_data])\n",
    "\n",
    "    # Create a DataLoader\n",
    "    batch_size = 8\n",
    "    train_dataset = TensorDataset(input_tensors['input_ids'], \n",
    "                                input_tensors['attention_mask'], \n",
    "                                input_tensors['token_type_ids'], \n",
    "                                label_tensors)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    optimizer = AdamW(tapas.parameters(), lr=1e-6)\n",
    "    tapas.train()\n",
    "\n",
    "    # Training loop with batching\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for batch in train_loader:\n",
    "            input_ids, attention_mask, token_type_ids, labels = [x.to(device) for x in batch]\n",
    "            inputs = {\n",
    "                \"input_ids\": input_ids, \n",
    "                \"attention_mask\": attention_mask, \n",
    "                \"token_type_ids\": token_type_ids\n",
    "            }\n",
    "\n",
    "            outputs = tapas(**inputs, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {total_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "# product_for_cls_path = \"./data/product_for_cls.csv\"\n",
    "movie_for_cls_path = \"./data/movie_for_cls.csv\"\n",
    "adult_path = \"./data/adult.csv\"\n",
    "bank_path = \"./data/bank.csv\"\n",
    "heart_path = \"./data/heart.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning datasets #\n",
    "\n",
    "# product_for_cls = JSONDataset(product_for_cls_path, tokenizer, path_is='csv')\n",
    "# product_for_cls_bert = JSONDataset(product_for_cls_path, tokenizer, path_is='csv', version='bert')\n",
    "\n",
    "movie_for_cls = JSONDataset(movie_for_cls_path, tokenizer, path_is='csv')\n",
    "movie_for_cls_bert = JSONDataset(movie_for_cls_path, tokenizer, path_is='csv', version='bert')\n",
    "\n",
    "adult = JSONDataset(adult_path, tokenizer, path_is='csv')\n",
    "adult_bert = JSONDataset(adult_path, tokenizer, path_is='csv', version='bert')\n",
    "\n",
    "bank = JSONDataset(bank_path, tokenizer, path_is='csv')\n",
    "bank_bert = JSONDataset(bank_path, tokenizer, path_is='csv', version='bert')\n",
    "\n",
    "heart = JSONDataset(heart_path, tokenizer, path_is='csv')\n",
    "heart_bert = JSONDataset(heart_path, tokenizer, path_is='csv', version='bert')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate pre-trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_movie' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate pre-trained (including domain-specific) models\u001b[39;00m\n\u001b[1;32m      3\u001b[0m models \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert_base\u001b[39m\u001b[38;5;124m\"\u001b[39m: (bert_base, tokenizer),\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtapas\u001b[39m\u001b[38;5;124m\"\u001b[39m: (tapas, tapas_tokenizer),\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtabert\u001b[39m\u001b[38;5;124m\"\u001b[39m: (tabert, tokenizer),\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert_product\u001b[39m\u001b[38;5;124m\"\u001b[39m: (bert_product, tokenizer),\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbert_movie\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[43mbert_movie\u001b[49m, tokenizer),\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mours_product\u001b[39m\u001b[38;5;124m\"\u001b[39m: (ours_product, tokenizer),\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mours_movie\u001b[39m\u001b[38;5;124m\"\u001b[39m: (ours_movie, tokenizer)\n\u001b[1;32m     11\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_movie' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate pre-trained (including domain-specific) models\n",
    "\n",
    "models = {\n",
    "    \"bert_base\": (bert_base, tokenizer),\n",
    "    \"tapas\": (tapas, tapas_tokenizer),\n",
    "    \"tabert\": (tabert, tokenizer),\n",
    "    \"bert_product\": (bert_product, tokenizer),\n",
    "    \"bert_movie\": (bert_movie, tokenizer),\n",
    "    \"ours_product\": (ours_product, tokenizer),\n",
    "    \"ours_movie\": (ours_movie, tokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Product_test\n",
    "# results = {}\n",
    "# for name, (model, tokenizer) in models.items():\n",
    "#     X_train, X_test, y_train, y_test = prepare_Xy(product_for_cls_path, model, tokenizer, seed=42)\n",
    "#     results[name] = train_eval_rf(X_train, X_test, y_train, y_test, seed=42)\n",
    "\n",
    "# # Print results\n",
    "# for model_name, metrics in results.items():\n",
    "#     print(f\"Metrics for {model_name} in product_for_cls:\")\n",
    "#     print(f\"\\t{metrics['precision']: .4f}\")\n",
    "#     print(f\"\\t{metrics['recall']: .4f}\")\n",
    "#     print(f\"\\t{metrics['f1_score']: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Movie_test\n",
    "results = {}\n",
    "for name, (model, tokenizer) in models.items():\n",
    "    X_train, X_test, y_train, y_test = prepare_Xy(movie_for_cls_path, model, tokenizer, seed=42)\n",
    "    results[name] = train_eval_rf(X_train, X_test, y_train, y_test, seed=42)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Metrics for {model_name} in movie_for_cls:\")\n",
    "    print(f\"\\t{metrics['precision']: .4f}\")\n",
    "    print(f\"\\t{metrics['recall']: .4f}\")\n",
    "    print(f\"\\t{metrics['f1_score']: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for bert_base in adult:\n",
      "\t 0.7607\n",
      "\t 0.8558\n",
      "\t 0.8054\n",
      "Metrics for tapas in adult:\n",
      "\t 0.7615\n",
      "\t 0.7981\n",
      "\t 0.7793\n",
      "Metrics for tabert in adult:\n",
      "\t 0.7607\n",
      "\t 0.8558\n",
      "\t 0.8054\n",
      "Metrics for ours_movie in adult:\n",
      "\t 0.6522\n",
      "\t 0.7212\n",
      "\t 0.6849\n"
     ]
    }
   ],
   "source": [
    "# Adult\n",
    "results = {}\n",
    "for name, (model, tokenizer) in models.items():\n",
    "    X_train, X_test, y_train, y_test = prepare_Xy(adult_path, model, tokenizer, seed=42)\n",
    "    results[name] = train_eval_rf(X_train, X_test, y_train, y_test, seed=42)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Metrics for {model_name} in adult:\")\n",
    "    print(f\"\\t{metrics['precision']: .4f}\")\n",
    "    print(f\"\\t{metrics['recall']: .4f}\")\n",
    "    print(f\"\\t{metrics['f1_score']: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for bert_base in bank:\n",
      "\t 0.7788\n",
      "\t 0.7788\n",
      "\t 0.7788\n",
      "Metrics for tapas in bank:\n",
      "\t 0.7670\n",
      "\t 0.7596\n",
      "\t 0.7633\n",
      "Metrics for tabert in bank:\n",
      "\t 0.7788\n",
      "\t 0.7788\n",
      "\t 0.7788\n",
      "Metrics for ours_movie in bank:\n",
      "\t 0.7551\n",
      "\t 0.7115\n",
      "\t 0.7327\n"
     ]
    }
   ],
   "source": [
    "# Bank\n",
    "results = {}\n",
    "for name, (model, tokenizer) in models.items():\n",
    "    X_train, X_test, y_train, y_test = prepare_Xy(bank_path, model, tokenizer, seed=42)\n",
    "    results[name] = train_eval_rf(X_train, X_test, y_train, y_test, seed=42)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Metrics for {model_name} in bank:\")\n",
    "    print(f\"\\t{metrics['precision']: .4f}\")\n",
    "    print(f\"\\t{metrics['recall']: .4f}\")\n",
    "    print(f\"\\t{metrics['f1_score']: .4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics for bert_base in heart:\n",
      "\t 0.9200\n",
      "\t 0.8598\n",
      "\t 0.8889\n",
      "Metrics for tapas in heart:\n",
      "\t 0.9000\n",
      "\t 0.8411\n",
      "\t 0.8696\n",
      "Metrics for tabert in heart:\n",
      "\t 0.9200\n",
      "\t 0.8598\n",
      "\t 0.8889\n",
      "Metrics for ours_movie in heart:\n",
      "\t 0.8660\n",
      "\t 0.7850\n",
      "\t 0.8235\n"
     ]
    }
   ],
   "source": [
    "# Heart\n",
    "results = {}\n",
    "for name, (model, tokenizer) in models.items():\n",
    "    X_train, X_test, y_train, y_test = prepare_Xy(heart_path, model, tokenizer, seed=42)\n",
    "    results[name] = train_eval_rf(X_train, X_test, y_train, y_test, seed=42)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Metrics for {model_name} in heart:\")\n",
    "    print(f\"\\t{metrics['precision']: .4f}\")\n",
    "    print(f\"\\t{metrics['recall']: .4f}\")\n",
    "    print(f\"\\t{metrics['f1_score']: .4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fine-tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Set Fine-tuning Domain ##########\n",
    "training_domain = movie_for_cls\n",
    "training_domain_bert = movie_for_cls_bert\n",
    "training_domain_path = movie_for_cls_path\n",
    "##########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune models (BERT, TaBERT, Ours-product, Ours-movie)\n",
    "\n",
    "# Data Collator\n",
    "jsonbert_data_collator = JSONDataCollator(\n",
    "    tokenizer=tokenizer,\n",
    "    hybrid_epochs=4\n",
    ")\n",
    "bert_data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=True,\n",
    "    mlm_probability=0.15\n",
    ")\n",
    "\n",
    "\n",
    "# Create Dataloaders\n",
    "jsonbert_train_dataloader = DataLoader(\n",
    "    training_domain,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=jsonbert_data_collator,\n",
    ")\n",
    "\n",
    "bert_train_dataloader = DataLoader(\n",
    "    training_domain_bert,\n",
    "    batch_size=8,\n",
    "    shuffle=True,\n",
    "    collate_fn=bert_data_collator,\n",
    ")\n",
    "\n",
    "\n",
    "# Hyperparameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "learning_rate = 1e-6\n",
    "epochs = 6\n",
    "\n",
    "# Optimizers and Schedulers for each model\n",
    "optimizers = {}\n",
    "schedulers = {}\n",
    "\n",
    "# Fine-tuning models\n",
    "optimizers[\"bert_base\"], schedulers[\"bert_base\"] = create_optimizer_and_scheduler(bert_base, bert_train_dataloader, 1e-6, 6)\n",
    "print(\"\\nFine-tuning bert_base...\")\n",
    "fine_tune_model(bert_base, bert_train_dataloader, optimizers[\"bert_base\"], schedulers[\"bert_base\"], device, epochs)\n",
    "\n",
    "optimizers[\"tabert\"], schedulers[\"tabert\"] = create_optimizer_and_scheduler(tabert, bert_train_dataloader, 1e-6, 6)\n",
    "print(\"\\nFine-tuning tabert...\")\n",
    "fine_tune_model(tabert, bert_train_dataloader, optimizers[\"tabert\"], schedulers[\"tabert\"], device, epochs)\n",
    "\n",
    "optimizers[\"ours_product\"], schedulers[\"ours_product\"] = create_optimizer_and_scheduler(ours_product, jsonbert_train_dataloader, 1e-6, 6)\n",
    "print(\"\\nFine-tuning ours_product...\")\n",
    "fine_tune_model(ours_product, jsonbert_train_dataloader, optimizers[\"ours_product\"], schedulers[\"ours_product\"], device, epochs)\n",
    "\n",
    "optimizers[\"ours_movie\"], schedulers[\"ours_movie\"] = create_optimizer_and_scheduler(ours_movie, jsonbert_train_dataloader, 1e-6, 6)\n",
    "print(\"\\nFine-tuning ours_movie...\")\n",
    "fine_tune_model(ours_movie, jsonbert_train_dataloader, optimizers[\"ours_movie\"], schedulers[\"ours_movie\"], device, epochs)\n",
    "\n",
    "optimizers[\"bert_product\"], schedulers[\"bert_product\"] = create_optimizer_and_scheduler(bert_product, jsonbert_train_dataloader, 1e-6, 6)\n",
    "print(\"\\nFine-tuning bert_product...\")\n",
    "fine_tune_model(bert_product, jsonbert_train_dataloader, optimizers[\"bert_product\"], schedulers[\"bert_product\"], device, epochs)\n",
    "\n",
    "optimizers[\"bert_movie\"], schedulers[\"bert_movie\"] = create_optimizer_and_scheduler(bert_movie, jsonbert_train_dataloader, 1e-6, 6)\n",
    "print(\"\\nFine-tuning bert_movie...\")\n",
    "fine_tune_model(bert_movie, jsonbert_train_dataloader, optimizers[\"bert_movie\"], schedulers[\"bert_movie\"], device, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune TaPas\n",
    "\n",
    "fine_tune_tapas(tapas, training_domain_path, epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate fine-tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"bert_base\": (bert_base, tokenizer),\n",
    "    \"tapas\": (tapas, tapas_tokenizer),\n",
    "    \"tabert\": (tabert, tokenizer),\n",
    "    \"bert_product\": (bert_product, tokenizer),\n",
    "    \"bert_movie\": (bert_movie, tokenizer),\n",
    "    \"ours_product\": (ours_product, tokenizer),\n",
    "    \"ours_movie\": (ours_movie, tokenizer)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification on trainined domain\n",
    "results = {}\n",
    "for name, (model, tokenizer) in models.items():\n",
    "    X_train, X_test, y_train, y_test = prepare_Xy(training_domain_path, model, tokenizer, seed=42)\n",
    "    results[name] = train_eval_rf(X_train, X_test, y_train, y_test, seed=42)\n",
    "\n",
    "# Print results\n",
    "for model_name, metrics in results.items():\n",
    "    print(f\"Metrics for {model_name} in trained domain:\")\n",
    "    print(f\"\\t{metrics['precision']: .4f}\")\n",
    "    print(f\"\\t{metrics['recall']: .4f}\")\n",
    "    print(f\"\\t{metrics['f1_score']: .4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
