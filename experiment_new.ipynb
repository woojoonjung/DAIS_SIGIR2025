{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used.\n"
     ]
    }
   ],
   "source": [
    "# Device\n",
    "\n",
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    print(\"GPU is available and will be used.\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"No GPU available, using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available and will be used.\n"
     ]
    }
   ],
   "source": [
    "#Imports\n",
    "\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import normalized_mutual_info_score, adjusted_rand_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import (\n",
    "    BertTokenizer, BertConfig, BertForMaskedLM, DataCollatorForLanguageModeling,\n",
    "    TapasTokenizer, TapasForMaskedLM,\n",
    "    AdamW, get_scheduler\n",
    ")\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from model_complete import JSONBERT_COMPLETE\n",
    "from dataset import JSONDataset, JSONDataCollator, create_data\n",
    "\n",
    "import sys\n",
    "sys.path.append('/root/woojun/')\n",
    "\n",
    "from utils import (\n",
    "    _serialize_vanilla,\n",
    "    _serialize,\n",
    "    tokenize_table,\n",
    "    _find_positions,\n",
    "    mask_entry,\n",
    "    predict_masked_tokens,\n",
    "    evaluate_masked_prediction,\n",
    "    train_eval_rf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer & config\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "config = BertConfig.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT loaded from ./models/movie_complete/epoch-9\n"
     ]
    }
   ],
   "source": [
    "# Models\n",
    "\n",
    "# BERT\n",
    "bert_base = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "bert_base = bert_base.to(device)\n",
    "\n",
    "# TaPas\n",
    "tapas_name = \"google/tapas-base-masklm\"\n",
    "tapas_tokenizer = TapasTokenizer.from_pretrained(tapas_name)\n",
    "tapas = TapasForMaskedLM.from_pretrained(tapas_name)\n",
    "tapas.to(device)\n",
    "\n",
    "# Ours\n",
    "ours_path_movie = './models/movie_complete/epoch-9'\n",
    "ours_movie = JSONBERT_COMPLETE(config, tokenizer, ours_path_movie)\n",
    "ours_movie = ours_movie.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "def prepare_Xy(df, model, tokenizer, target='filename', seed=42):\n",
    "    data = df.to_dict(orient=\"records\")\n",
    "    y = df[target].values\n",
    "    X = np.array([get_table_embedding(entry, model, tokenizer, target) for entry in data])\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-English table: Movie_adorocinema.com_October2023.json\n",
      "Skipping non-English table: Movie_afisha.ru_October2023.json\n",
      "Skipping non-English table: Movie_ak.sv_October2023.json\n",
      "Skipping non-English table: Movie_allcinema.net_October2023.json\n",
      "Skipping non-English table: Movie_allocine.fr_October2023.json\n",
      "Skipping non-English table: Movie_arte.tv_October2023.json\n",
      "Skipping non-English table: Movie_cinecitta.de_October2023.json\n",
      "Skipping non-English table: Movie_cinefil.com_October2023.json\n",
      "Skipping non-English table: Movie_cinema-rank.net_October2023.json\n",
      "Skipping non-English table: Movie_cinematoday.jp_October2023.json\n",
      "Skipping non-English table: Movie_comingsoon.it_October2023.json\n",
      "Skipping non-English table: Movie_cpop.it_October2023.json\n",
      "Skipping non-English table: Movie_crank-in.net_October2023.json\n",
      "Skipping non-English table: Movie_dok-film.net_October2023.json\n",
      "Skipping non-English table: Movie_domkino.tv_October2023.json\n",
      "Skipping non-English table: Movie_ecranlarge.com_October2023.json\n",
      "Skipping non-English table: Movie_expansion.com_October2023.json\n",
      "Skipping non-English table: Movie_filmaffinity.com_October2023.json\n",
      "Skipping non-English table: Movie_filmnavi.ru_October2023.json\n",
      "Skipping non-English table: Movie_filmstarts.de_October2023.json\n",
      "Skipping non-English table: Movie_hinet.net_October2023.json\n",
      "Skipping non-English table: Movie_ign.com_October2023.json\n",
      "Skipping non-English table: Movie_jfc.org.il_October2023.json\n",
      "Skipping non-English table: Movie_kino-zeit.de_October2023.json\n",
      "Skipping non-English table: Movie_kino.de_October2023.json\n",
      "Skipping non-English table: Movie_kinoheld.de_October2023.json\n",
      "Skipping non-English table: Movie_kpn.com_October2023.json\n",
      "Skipping non-English table: Movie_lacinetek.com_October2023.json\n",
      "Skipping non-English table: Movie_mail.ru_October2023.json\n",
      "Skipping non-English table: Movie_moviebreak.de_October2023.json\n",
      "Skipping non-English table: Movie_moviejones.de_October2023.json\n",
      "Skipping non-English table: Movie_moviemeter.nl_October2023.json\n",
      "Skipping non-English table: Movie_moviewalker.jp_October2023.json\n",
      "Skipping non-English table: Movie_movistarplus.es_October2023.json\n",
      "Skipping non-English table: Movie_mymovies.it_October2023.json\n",
      "Skipping non-English table: Movie_myvideo.net.tw_October2023.json\n",
      "Skipping non-English table: Movie_nientepopcorn.it_October2023.json\n",
      "Skipping non-English table: Movie_onf.ca_October2023.json\n",
      "Skipping non-English table: Movie_ouest-france.fr_October2023.json\n",
      "Skipping non-English table: Movie_ovideo.ru_October2023.json\n",
      "Skipping non-English table: Movie_pb.wtf_October2023.json\n",
      "Skipping non-English table: Movie_pix-geeks.com_October2023.json\n",
      "Skipping non-English table: Movie_premiere.fr_October2023.json\n",
      "Skipping non-English table: Movie_scary-movies.de_October2023.json\n",
      "Skipping non-English table: Movie_screenweek.it_October2023.json\n",
      "Skipping non-English table: Movie_spielfilm.de_October2023.json\n",
      "Skipping non-English table: Movie_telerama.fr_October2023.json\n",
      "Skipping non-English table: Movie_timeout.ru_October2023.json\n",
      "Skipping non-English table: Movie_watcha.com_October2023.json\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "pretraining_movie_path = './data/pretraining_data_movie.jsonl'\n",
    "\n",
    "movie_path = './data/Movie_top100'\n",
    "\n",
    "movie = create_data(movie_path, path_is=\"test\", sample_num=20, pretraining_path=pretraining_movie_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping non-English table: Product_10x10.co.kr_October2023.json\n",
      "Skipping non-English table: Product_all.biz_October2023.json\n",
      "Skipping non-English table: Product_avito.ru_October2023.json\n",
      "Skipping non-English table: Product_com.ru_October2023.json\n",
      "Skipping non-English table: Product_docomo.ne.jp_October2023.json\n",
      "Skipping non-English table: Product_elektronikai-hulladek-felvasarlas.hu_October2023.json\n",
      "Skipping non-English table: Product_eltiempo.com_October2023.json\n",
      "Skipping non-English table: Product_fateful.hu_October2023.json\n",
      "Skipping non-English table: Product_havidijas-keresooptimalizalas.hu_October2023.json\n",
      "Skipping non-English table: Product_line.me_October2023.json\n",
      "Skipping non-English table: Product_made-in-china.com_October2023.json\n",
      "Skipping non-English table: Product_mattel.com_October2023.json\n",
      "Skipping non-English table: Product_numizmatik.ru_October2023.json\n",
      "Skipping non-English table: Product_odoo.com_October2023.json\n",
      "Skipping non-English table: Product_pp.ua_October2023.json\n",
      "Skipping non-English table: Product_profi.ru_October2023.json\n",
      "Skipping non-English table: Product_robotshop.com_October2023.json\n",
      "Skipping non-English table: Product_semana.com_October2023.json\n",
      "Skipping non-English table: Product_spb.ru_October2023.json\n",
      "Skipping non-English table: Product_t-online.de_October2023.json\n",
      "Skipping non-English table: Product_taobao.com_October2023.json\n",
      "Skipping non-English table: Product_tiki.vn_October2023.json\n",
      "Skipping non-English table: Product_todocoleccion.net_October2023.json\n",
      "Skipping non-English table: Product_udg.mx_October2023.json\n",
      "Skipping non-English table: Product_weboldal-webaruhaz-keszites-budapest.com_October2023.json\n",
      "Skipping non-English table: Product_yahoo.com_October2023.json\n",
      "Skipping non-English table: Product_yamaha.com_October2023.json\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "\n",
    "pretraining_product_path = './data/pretraining_data_product.jsonl'\n",
    "\n",
    "product_path = './data/Product_top100'\n",
    "\n",
    "product = create_data(product_path, path_is=\"test\", sample_num=20, pretraining_path=pretraining_product_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_clustering_experiment(X, y):\n",
    "#     # Convert labels to binary format\n",
    "#     unique_labels = np.unique(y)\n",
    "#     n_clusters = len(unique_labels)\n",
    "\n",
    "#     # Run K-Means clustering with the number of ground truth clusters\n",
    "#     kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "#     kmeans.fit(X)\n",
    "\n",
    "#     # Predict clusters for test data\n",
    "#     cluster_labels = kmeans.predict(X)\n",
    "\n",
    "#     # Evaluate clustering performance\n",
    "#     nmi = normalized_mutual_info_score(y, cluster_labels)\n",
    "#     print(f\"Normalized Mutual Information (NMI) on test data: {nmi:.2f}\")\n",
    "\n",
    "#     ari = adjusted_rand_score(y, cluster_labels)\n",
    "#     print(f\"Adjusted Rand Index (ARI) on test data: {ari:.2f}\")\n",
    "\n",
    "#     # Verify data sizes\n",
    "#     print(f\"X shape: {X.shape}, y length: {len(y)}\")\n",
    "\n",
    "#     # Check unique labels\n",
    "#     print(f\"Unique labels in y: {np.unique(y)}\")\n",
    "\n",
    "\n",
    "#     # Visualize clustering\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     plt.scatter(X[:, 0], X[:, 1], c=cluster_labels, cmap='tab20', marker='o', edgecolor='k')\n",
    "#     plt.title(f\"K-Means Clustering Results with {n_clusters} Clusters\")\n",
    "#     plt.xlabel(\"Feature 1\")\n",
    "#     plt.ylabel(\"Feature 2\")\n",
    "#     plt.legend(['Cluster ' + str(i) for i in range(n_clusters)])\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_df = pd.DataFrame(movie)\n",
    "# sampled_filenames = ['Movie_telescopefilm.com_October2023.json', 'Movie_tubitv.com_October2023.json']\n",
    "# sampled_data = [row for row in movie if row[\"filename\"] in sampled_filenames]\n",
    "# sampled_df = pd.DataFrame(sampled_data)\n",
    "# sampled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Export embeddings\n",
    "\n",
    "# data = sampled_df.to_dict(orient=\"records\")\n",
    "# sampled_df['our_embeddings'] = [get_table_embedding(entry, ours_movie, tokenizer, 'filename') for entry in data]\n",
    "# sampled_df['bert_embeddings'] = [get_table_embedding(entry, bert_base, tokenizer, 'filename') for entry in data]\n",
    "\n",
    "# csv_export_path = 'embeddings_from_our_model.csv'\n",
    "# sampled_df.to_csv(csv_export_path, index=False)\n",
    "# print(f'DataFrame exported to {csv_export_path}')\n",
    "\n",
    "# json_export_path = 'embeddings_from_our_model.json'\n",
    "# sampled_df.to_json(json_export_path, orient='records', indent=4)\n",
    "# print(f'DataFrame exported to {json_export_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = prepare_Xy(sampled_df, notsure_movie, tokenizer, 'filename')\n",
    "# run_clustering_experiment(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = prepare_Xy(sampled_df, ours_movie, tokenizer, 'filename')\n",
    "# run_clustering_experiment(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = prepare_Xy(sampled_df, bert_base, tokenizer, 'filename')\n",
    "# run_clustering_experiment(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = prepare_Xy(sampled_df, tapas, tapas_tokenizer, 'filename')\n",
    "# run_clustering_experiment(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Masked Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_INTERPOLATE loaded from ./models/movie_no_cl/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_NEWLOSS loaded from ./models/movie_alpha_0/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_NEWLOSS loaded from ./models/movie_alpha_1/epoch-9\n"
     ]
    }
   ],
   "source": [
    "from no_cl import JSONBERT_INTERPOLATE\n",
    "from no_ip_alpha_0 import JSONBERT_NEWLOSS_0\n",
    "from no_ip_alpha_1 import JSONBERT_NEWLOSS_1\n",
    "\n",
    "no_cl_path_movie = './models/movie_no_cl/epoch-9'\n",
    "alpha_0_path_movie = './models/movie_alpha_0/epoch-9'\n",
    "alpha_1_path_movie = './models/movie_alpha_1/epoch-9'\n",
    "no_hel_path_movie = './models/movie_no_hel/epoch-9'\n",
    "bert_path_movie = './models/movie_bert/epoch-9'\n",
    "\n",
    "\n",
    "no_cl_movie = JSONBERT_INTERPOLATE(config, tokenizer, no_cl_path_movie)\n",
    "no_cl_movie = no_cl_movie.to(device)\n",
    "\n",
    "alpha_0_movie = JSONBERT_NEWLOSS_0(config, tokenizer, alpha_0_path_movie)\n",
    "alpha_0_movie = alpha_0_movie.to(device)\n",
    "\n",
    "alpha_1_movie = JSONBERT_NEWLOSS_1(config, tokenizer, alpha_1_path_movie)\n",
    "alpha_1_movie = alpha_1_movie.to(device)\n",
    "\n",
    "no_hel_movie = BertForMaskedLM.from_pretrained(no_hel_path_movie, local_files_only=True)\n",
    "no_hel_movie = no_hel_movie.to(device)\n",
    "\n",
    "bert_movie = BertForMaskedLM.from_pretrained(bert_path_movie, local_files_only=True)\n",
    "bert_movie = bert_movie.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT loaded from ./models/product_complete/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_INTERPOLATE loaded from ./models/product_no_cl/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_NEWLOSS loaded from ./models/product_alpha_0/epoch-9\n",
      "Key embeddings are trainable!\n",
      "Pre-trained JSONBERT_NEWLOSS loaded from ./models/product_alpha_1/epoch-9\n"
     ]
    }
   ],
   "source": [
    "# Product\n",
    "\n",
    "ours_path_product = './models/product_complete/epoch-9'\n",
    "no_cl_path_product = './models/product_no_cl/epoch-9'\n",
    "alpha_0_path_product = './models/product_alpha_0/epoch-9'\n",
    "alpha_1_path_product = './models/product_alpha_1/epoch-9'\n",
    "no_hel_path_product = './models/product_no_hel/epoch-9'\n",
    "bert_path_product = './models/product_bert/epoch-9'\n",
    "\n",
    "ours_product = JSONBERT_COMPLETE(config, tokenizer, ours_path_product)\n",
    "ours_product = ours_product.to(device)\n",
    "\n",
    "no_cl_product = JSONBERT_INTERPOLATE(config, tokenizer, no_cl_path_product)\n",
    "no_cl_product = no_cl_product.to(device)\n",
    "\n",
    "alpha_0_product = JSONBERT_NEWLOSS_0(config, tokenizer, alpha_0_path_product)\n",
    "alpha_0_product = alpha_0_product.to(device)\n",
    "\n",
    "alpha_1_product = JSONBERT_NEWLOSS_1(config, tokenizer, alpha_1_path_product)\n",
    "alpha_1_product = alpha_1_product.to(device)\n",
    "\n",
    "no_hel_product = BertForMaskedLM.from_pretrained(no_hel_path_product, local_files_only=True)\n",
    "no_hel_product = no_hel_product.to(device)\n",
    "\n",
    "bert_product = BertForMaskedLM.from_pretrained(bert_path_product, local_files_only=True)\n",
    "bert_product = bert_product.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct / Total: 1843/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.5790%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:2699: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  text = normalize_for_match(row[col_index].text)\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/models/tapas/tokenization_tapas.py:1493: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cell = row[col_index]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct / Total: 1093/3869\n",
      "Model Accuracy on Masked Key Prediction: 0.2825%\n",
      "Correct / Total: 1660/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.5827%\n",
      "Correct / Total: 13617/32659\n",
      "Model Accuracy on Masked Value Prediction: 0.4169%\n",
      "Correct / Total: 3175/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.9975%\n",
      "Correct / Total: 3171/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.9962%\n",
      "Correct / Total: 2562/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.8049%\n",
      "Correct / Total: 3177/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.9981%\n",
      "Correct / Total: 3177/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.9981%\n",
      "Correct / Total: 2552/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.8018%\n",
      "Correct / Total: 2204/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.7736%\n",
      "Correct / Total: 2176/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.7638%\n",
      "Correct / Total: 2160/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.7582%\n",
      "Correct / Total: 2172/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.7624%\n",
      "Correct / Total: 2220/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.7792%\n",
      "Correct / Total: 1774/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.6227%\n"
     ]
    }
   ],
   "source": [
    "# In-domain: Movie\n",
    "\n",
    "# Pre-trained: BERT, TaPas, TaBERT\n",
    "evaluate_masked_prediction(movie, 'Key', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', tapas, tapas_tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(movie, 'Value', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', tapas, tapas_tokenizer)\n",
    "\n",
    "# Domain-specific pre-trained: Ours, No CL, No IP_a0, No IP_a1, No HEL, trained BERT\n",
    "evaluate_masked_prediction(movie, 'Key', ours_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', no_cl_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', alpha_0_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', alpha_1_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', no_hel_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Key', bert_movie, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(movie, 'Value', ours_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', no_cl_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', alpha_0_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', alpha_1_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', no_hel_movie, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', bert_movie, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct / Total: 1920/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.4638%\n",
      "Correct / Total: 1053/4448\n",
      "Model Accuracy on Masked Key Prediction: 0.2367%\n",
      "Correct / Total: 1430/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.5743%\n",
      "Correct / Total: 18640/48358\n",
      "Model Accuracy on Masked Value Prediction: 0.3855%\n",
      "Correct / Total: 4088/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.9874%\n",
      "Correct / Total: 4090/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.9879%\n",
      "Correct / Total: 3062/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.7396%\n",
      "Correct / Total: 4096/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.9894%\n",
      "Correct / Total: 4104/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.9913%\n",
      "Correct / Total: 3171/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.7659%\n",
      "Correct / Total: 1775/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.7129%\n",
      "Correct / Total: 1753/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.7040%\n",
      "Correct / Total: 1771/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.7112%\n",
      "Correct / Total: 1753/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.7040%\n",
      "Correct / Total: 1774/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.7124%\n",
      "Correct / Total: 1523/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.6116%\n"
     ]
    }
   ],
   "source": [
    "# In-domain: product\n",
    "\n",
    "# Pre-trained: BERT, TaPas, TaBERT\n",
    "evaluate_masked_prediction(product, 'Key', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', tapas, tapas_tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(product, 'Value', bert_base, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', tapas, tapas_tokenizer)\n",
    "\n",
    "# Domain-specific pre-trained: Ours, No CL, No IP_a0, No IP_a1, No HEL, trained BERT\n",
    "evaluate_masked_prediction(product, 'Key', ours_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', no_cl_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', alpha_0_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', alpha_1_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', no_hel_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Key', bert_product, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(product, 'Value', ours_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', no_cl_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', alpha_0_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', alpha_1_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', no_hel_product, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', bert_product, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct / Total: 3160/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.9928%\n",
      "Correct / Total: 2066/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.7252%\n",
      "Correct / Total: 2647/3183\n",
      "Model Accuracy on Masked Key Prediction: 0.8316%\n",
      "Correct / Total: 1721/2849\n",
      "Model Accuracy on Masked Value Prediction: 0.6041%\n",
      "Correct / Total: 4082/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.9860%\n",
      "Correct / Total: 1599/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.6422%\n",
      "Correct / Total: 3130/4140\n",
      "Model Accuracy on Masked Key Prediction: 0.7560%\n",
      "Correct / Total: 1447/2490\n",
      "Model Accuracy on Masked Value Prediction: 0.5811%\n"
     ]
    }
   ],
   "source": [
    "# Cross-domain\n",
    "\n",
    "# Trained on Product -> Tested on Movie\n",
    "evaluate_masked_prediction(movie, 'Key', ours_product, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', ours_product, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(movie, 'Key', bert_product, tokenizer)\n",
    "evaluate_masked_prediction(movie, 'Value', bert_product, tokenizer)\n",
    "\n",
    "\n",
    "# Trained on Movie -> Tested on Product\n",
    "evaluate_masked_prediction(product, 'Key', ours_movie, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', ours_movie, tokenizer)\n",
    "\n",
    "evaluate_masked_prediction(product, 'Key', bert_movie, tokenizer)\n",
    "evaluate_masked_prediction(product, 'Value', bert_movie, tokenizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
